<!DOCTYPE html>
<html>
	<head>
		
<title>自然语言处理基础-无限进步</title>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<link rel="shortcut icon" type="image/x-icon" href="/image/shengdanwu.png">

<link rel="stylesheet" href="/css/index.css">



<meta name="keywords" content="人工智能,">
<meta name="description" content="中国科学院大学《自然语言处理基础》期末复习">


<script src="/js/jquery.min.js"></script>


<script src="/js/index.js"></script>


<script src="/js/fancybox.umd.js"></script>


<script src="/js/fancybox-images.js"></script>


<script src="/js/gitalk.min.js"></script>


<script src="/js/hljs.min.js"></script>
 
<script>hljs.highlightAll();</script>

	<meta name="generator" content="Hexo 8.1.1"></head>

	<body>
		
	<div class="header">
		<div class="header-top" id="header-top">
			<div class="h-left">
				<a href="/">
					<img src="/image/shengdanwu.png" alt="Quiet">
				</a>
			</div>
			<div class="h-right">
				<ul>
					
						
								<li>
									<a href="/">
										HOME
									</a>
									<span class="dot"></span>
								</li>
								
									
						
								<li>
									<a href="/archives">
										ARCHIVE
									</a>
									<span class="dot"></span>
								</li>
								
									
						
								<li>
									<a href="/categories">
										CATEGORIES
									</a>
									<span class="dot"></span>
								</li>
								
									
						
								<li>
									<a href="/tags">
										TAGS
									</a>
									<span class="dot"></span>
								</li>
								
									
						
								<li>
									<a href="/links">
										LINKS
									</a>
									<span class="dot"></span>
								</li>
								
									
						
								<li>
									<a href="/about">
										ABOUT
									</a>
									<span class="dot"></span>
								</li>
								
									
				</ul>
			</div>
			<div class="h-right-close">
				<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24" width="24" height="24">
					<path fill="none" d="M0 0h24v24H0z" />
					<path d="M3 4h18v2H3V4zm0 7h18v2H3v-2zm0 7h18v2H3v-2z" fill="rgba(68,68,68,1)" />
				</svg>
			</div>
		</div>
	</div>
	<div class="sidebar">
    <div class="topo">
        <h2>Ram</h2>
    </div>
    <ul>
        
        <li>
            <a href="/">HOME</a>
        </li>
        
        <li>
            <a href="/archives">ARCHIVE</a>
        </li>
        
        <li>
            <a href="/categories">CATEGORIES</a>
        </li>
        
        <li>
            <a href="/tags">TAGS</a>
        </li>
        
        <li>
            <a href="/links">LINKS</a>
        </li>
        
        <li>
            <a href="/about">ABOUT</a>
        </li>
        
    </ul>
    <div class="my_foot">
        
        <a target="_blank" rel="noopener" href="https://github.com/RamBree">
            <img src="https://cdn.jsdelivr.net/gh/duogongneng/MyBlogImg/imggithub.png" alt="Quiet主题">
        </a>
        
    </div>
</div>
<div class='shelter'>
</div>
<style>
    .shelter{
        background-color: #333;
        opacity:0.5;
        cursor: pointer;
        display: none; 
        position: fixed;
        left: 0;
        top: 0; 
        right: 0;
        bottom: 0;
        z-index: 1998;
    }
    .sidebar {
        width: 66%;
        height: 100%;
        position: fixed;
        top: 0;
        right: -100%;
        bottom: 0;
        background: #fff;
        z-index: 1999;
        text-align: center;
        box-shadow: -6px 0 20px rgba(98, 94, 94, .815);
    }

    .topo {
        width: 100%;
        height: 200px;
        background: url(https://api.ixiaowai.cn/gqapi/gqapi.php) no-repeat;
        background-size: 100% 100%;
        position: relative;
        display: flex;
        align-items: flex-end
    }

    .topo h2 {
        color: #fff;
        z-index: 1;
        position: relative;
        margin: 0 0 10px 10px;
        font-size: 1.2em;
        box-sizing: border-box
    }

    .topo:before {
        content: '';
        background-image: url(/image/pattern.png);
        background-repeat: repeat;
        height: 100%;
        left: 0;
        position: absolute;
        top: 0;
        width: 100%;
        z-index: 1
    }

    .sidebar ul {
        width: 100%;
        margin-top: 50px
    }

    .sidebar ul li {
        height: 50px;
        list-style: none;
        font-size: 1.2em;
        text-align: right;
        margin-right: 10px
    }

    .sidebar ul li a {
        display: grid;
        color: #5d606a;
        text-overflow: ellipsis;
        width: 100%;
        text-decoration: none
    }

    .my_foot {
        width: 100%;
        padding: 10px;
        margin-bottom: 10px;
        position: absolute;
        bottom: 0
    }

    .my_foot a {
        text-decoration: none;
        margin-right: 10px;
        display: inline-block
    }

    .my_foot a img {
        width: 30px;
        height: 30px
    }
</style>

<script>
    $( function () {
	$( '.h-right-close>svg' )
		.click( function () {
			$( '.sidebar' )
				.animate( {
					right: "0"
				}, 500 );
			$( '.shelter' )
				.fadeIn( "slow" )
		} );
	$( '.shelter' )
		.click( function ( e ) {
			$( '.sidebar' )
				.animate( {
					right: "-100%"
				}, 500 );
			$( '.shelter' )
				.fadeOut( "slow" )
		} )
} )

</script>

<div class="post">
    <div class="post-header-background post-header-img"
    style="background: url('/image/chainsaw-man-3840x2160-24469.jpg')" 
>
    <div class="post-header-background-content">
        <ul class="post-header-tag">
            
            
            <li><a href="/tags/人工智能">人工智能</a></li>
            
            
        </ul>
        
        <h1>自然语言处理基础</h1>
        <div class="post-header-info">
            <div class="post-header-info-author">
                
                    <svg t="1604839279282" class="icon" viewBox="0 0 1024 1024" version="1.1"
                        xmlns="http://www.w3.org/2000/svg" p-id="2901" width="20" height="20">
                        <path
                            d="M513 956.3c-247.7 0-448-200.3-448-448S265.3 66.2 513 66.2s448 200.3 448 448-200.3 442.1-448 442.1z m0-830.9c-212.2 0-388.8 170.7-388.8 388.8C124.2 726.3 294.9 903 513 903c212.2 0 388.8-170.7 388.8-388.8S725.2 125.4 513 125.4z m0 430.2c-94.2 0-170.7-76.5-170.7-170.7S418.8 207.8 513 207.8s170.7 76.5 170.7 170.7S607.2 555.6 513 555.6z m0-289.1c-64.6 0-112 52.8-112 112s47.4 117.9 112 117.9 112-52.8 112-112-47.4-117.9-112-117.9z m0 689.8c-135.7 0-259-58.7-341.9-158.9l-11.8-17.8 11.8-17.8c76.5-117.9 206.2-188.5 347.8-188.5 135.7 0 265 64.6 341.9 182.6l11.8 17.8-11.8 17.8C778 897.1 648.7 956.3 513 956.3zM230.3 773.2C300.9 849.7 406.9 897 513 897c112 0 218.1-47.4 288.6-129.8-70.5-88.2-170.7-135.6-282.7-135.6s-218.1 53.3-288.6 141.6z"
                            p-id="2902" fill="#ffffff"></path>
                    </svg>
                    
                <span class="post-header-info-author-text"> <a href="../../about">Ram</a></span>
                <div class="post-header-info-author-categories">
                    
                         <a href="/categories/UCAS课程学习" target="_blank" >UCAS课程学习</a>
                    
                </div>
                <p>2026-01-19 20:08:26</p>
            </div>
        </div>
    </div>
</div>
    <div class="post-content" id="content">
  
  <div id="article" class="post-content-info">
    

    <h1 id="自然语言处理基础期末复习"><a href="#自然语言处理基础期末复习" class="headerlink" title="自然语言处理基础期末复习"></a>自然语言处理基础期末复习</h1><blockquote>
<p> <strong>授课教师</strong>：胡玥、曹亚男、方芳</p>
<p> <strong>考试信息</strong>：题目更难、覆盖更广、大模型更多了。老师说看完这些点能考到80、90分。主观题只需要核心理念（不需要完整公式）。</p>
</blockquote>
<p>前面的是填空和简答题。后面三个方面是主观题。（曹老师说这些点有95分）复习的时候就以下面这些为重点来学习，然后对一些关键性的概念也会在文中提及。</p>
<p><img src="/2026/01/19/NLP/NLP%E8%80%83%E8%AF%95%E5%A4%A7%E7%BA%B2.HEIC" alt="image.png"></p>
<h2 id="绪论"><a href="#绪论" class="headerlink" title="绪论"></a>绪论</h2><p>自然语言处理（Natural Language Processing，简称NLP）是利用计算机为工具，对人类特有的书面形式和口头形式的自然语言的信息进行各种类型处理和加工的技术。</p>
<p>自然语言处理是人工智能的一个分支，用于分析、理解和生成自然语言，以方便人和计算机设备以及人与人之间的交流</p>
<p>NLP核心任务：信息抽取、文本分类、情感分析、问答系统、机器阅读理解、智能对话、自动文摘、机器翻译</p>
<p><strong>NLP任务的机器学习方法经历了五次范式变迁</strong>——<em><strong>考点1</strong></em></p>
<p><img src="/2026/01/19/NLP/image-20260122173222259.png" alt="image-20260122173222259"></p>
<h4 id="P1-非神经网络时代的完全监督学习–特征工程（Fully-Supervised-Learning-Non-Neural-Network）"><a href="#P1-非神经网络时代的完全监督学习–特征工程（Fully-Supervised-Learning-Non-Neural-Network）" class="headerlink" title="P1.非神经网络时代的完全监督学习–特征工程（Fully Supervised Learning, Non-Neural Network）"></a>P1.非神经网络时代的完全监督学习–特征工程（Fully Supervised Learning, Non-Neural Network）</h4><p><strong>模型</strong>：概率模型，如贝叶斯，隐马尔可夫，最大熵，条件随机场等</p>
<p><strong>特点</strong>：人工进行大量的特征模版定义，一般采用流水线解决方案</p>
<p><strong>优点</strong>：可解释性强</p>
<p><strong>缺点</strong>：解决问题方法复杂</p>
<blockquote>
<p>对比深度学习方法：深度学习方法解决问题方法简单，但可解释性差</p>
</blockquote>
<p>以机器翻译任务为例说明<strong>概率统计方法</strong>和<strong>深度学习&#x2F;神经网络方法</strong>的区别</p>
<p><strong>概率统计法机器翻译</strong>：树到树的翻译模型</p>
<ol>
<li>句法分析：将源语言句子分析为一棵句法结构树（短语结构树）</li>
<li>树到树的转换：递归地将源语言句子的句法结构树转换为目标语言句子的句法结构树，拼接叶结点得到译文</li>
</ol>
<p>特点：流水线处理过程，中间过程复杂，但解释性强。</p>
<p><strong>深度学习法机器翻译</strong>：神经网络模型</p>
<p>特点：只需双语平行语料进行端到端训练，翻译过程不需词法分析&#x2F;句法分析等中间过程，直接端到端翻译 。方法简单，但解释性差。</p>
<p>以情感分类说明后四种范式的区别</p>
<h4 id="P2-基于神经网络的完全监督学习–架构工程-Fully-Supervised-Learning-Neural-Network"><a href="#P2-基于神经网络的完全监督学习–架构工程-Fully-Supervised-Learning-Neural-Network" class="headerlink" title="P2.基于神经网络的完全监督学习–架构工程(Fully Supervised Learning, Neural Network)"></a>P2.基于神经网络的完全监督学习–架构工程(Fully Supervised Learning, Neural Network)</h4><p><strong>模型</strong>：各种神经网络模型（CNN，RNN， Transformer，GNN 等）</p>
<p><strong>特点</strong>：模型自动提取特征，一般端到端解决方案</p>
<p><strong>优点</strong>：处理问题的方法变得简单</p>
<p><strong>缺点</strong>：需要大量标注数据（有监督），可解释性性差</p>
<p>情感分类</p>
<p>文本：这个餐厅的服务真不错 → 情感分类标签</p>
<p>方法：建模神经网将文本形成文本表示，然后进行分类</p>
<p><img src="/2026/01/19/NLP/image-20260122174301320.png" alt="image-20260122174301320"></p>
<h4 id="P3-预训练，精调范式-–目标工程-Pre-train-Fine-tune"><a href="#P3-预训练，精调范式-–目标工程-Pre-train-Fine-tune" class="headerlink" title="P3.预训练，精调范式 –目标工程 (Pre-train, Fine-tune)"></a>P3.预训练，精调范式 –目标工程 (Pre-train, Fine-tune)</h4><p><strong>特点</strong>：引入各种辅助任务loss，将其添加到预训练模型中，然后继续pre-training，以便让其适配下游任务，之后，通过引入额外的参数，用特定任务的目标函数对模型进行微调，使其更适配下游任务。研究重点转向了目标工程，设计在预训练和微调阶段使用的训练目标</p>
<p><strong>基本思想</strong>：自然语言处理任务往往用有监督方法学习，但<strong>标注数据有限</strong>，预训练方法可以通过自监督学习从大规模数据中获得与<strong>具体任务无关的预训练模型</strong> ，然后用训练好的预训练模型提高<strong>下游任务的性能</strong>。</p>
<p><strong>数据特点</strong>：需要领域数据进行任务微调</p>
<p><img src="/2026/01/19/NLP/image-20260122175102413.png" alt="image-20260122175102413"></p>
<h4 id="P4-预训练，提示，预测范式–prompt挖掘工程-（Pre-train-Prompt-Predict）"><a href="#P4-预训练，提示，预测范式–prompt挖掘工程-（Pre-train-Prompt-Predict）" class="headerlink" title="P4.预训练，提示，预测范式–prompt挖掘工程 （Pre-train, Prompt, Predict）"></a>P4.预训练，提示，预测范式–prompt挖掘工程 （Pre-train, Prompt, Predict）</h4><blockquote>
<p><strong>Prompt</strong> is the technique of <strong>making better use of the Knowledge</strong> from the pre-trained model by <strong>adding additional texts to the input</strong></p>
</blockquote>
<p><strong>特点</strong>：<strong>不通过目标工程</strong>使预训练的语言模型（LM）适应下游任务，而是将下游任务建模的方式重新定义**（Reformulate）<strong>，通过利用合适prompt实现不对预训练语言模型改动太多，尽量在</strong>原始LM**上解决任务的问题</p>
<p><strong>核心思想</strong>：改变任务形式利用预训练模型完成任务（用于小样本学习或半监督学习，某些场景下甚至能做到零样本学习。）</p>
<p><strong>数据特点</strong>： 少量（无）的任务数据</p>
<blockquote>
<p>prompt learning激活了类似于小样本学习等场景</p>
</blockquote>
<p><img src="/2026/01/19/NLP/image-20260122180024520.png" alt="image-20260122180024520"></p>
<p>方法：给输入的文本增加一个前缀或者后缀描述，并且Mask掉某些Token，转换为完形填空问题，转换要尽可能与原来的句子组成一句自然的话</p>
<p><img src="/2026/01/19/NLP/image-20260122180155407.png" alt="image-20260122180155407"></p>
<p><img src="/2026/01/19/NLP/image-20260122181135567.png" alt="image-20260122181135567"></p>
<p>通过任务转换可以用MLM模型给出预测结果，而MLM模型的训练可以不需要监督数据，因此理论上这能够实现零样本学习。（如用少量任务样本微调一下模型，效果更好）</p>
<h4 id="P5-大模型LLM-（Chat-GPT）"><a href="#P5-大模型LLM-（Chat-GPT）" class="headerlink" title="P5. 大模型LLM （Chat GPT）"></a>P5. 大模型LLM （Chat GPT）</h4><p><strong>特点</strong>：通用预训练语言模型（大模型），将下游任务统一为生成式任务，通过提示学习，上下文学习，思维链，检索增强等方式完成各类任务</p>
<p><img src="/2026/01/19/NLP/image-20260122181004820.png" alt="image-20260122181004820"></p>
<p>在大模型时代，依靠大模型强大的语言生成能力和理解能力，已经可以使用<strong>指令</strong>去激发模型的各种能力，进而用<strong>自然对话的方式</strong>来解决情感分析等基础任务了</p>
<p><em>五个范式的总结</em></p>
<p><img src="/2026/01/19/NLP/image-20260122174912226.png" alt="image-20260122174912226"></p>
<p><em>授课体系</em></p>
<p><img src="/2026/01/19/NLP/image-20260122181300271.png" alt="image-20260122181300271"></p>
<h2 id="第二章-数据资源"><a href="#第二章-数据资源" class="headerlink" title="第二章 数据资源"></a>第二章 数据资源</h2><p><img src="/2026/01/19/NLP/image-20260122223726403.png" alt="image-20260122223726403"></p>
<p>语料库：指存放在计算机里的原始语料文本或经过加工后带有语言学信息标注的语料文本。</p>
<p>语言知识库：从大量的实例语料中提炼、抽象、概括出来的系统的语言知识，如电子词典、句法规则库、词法分析规则库等。</p>
<p>指令微调数据集: 该类数据集是有标注数据集，主要对大语言模型进行符合人类习惯输出的微调训练。一般有人工标注数据集和用模型合成方法生成的数据集</p>
<h2 id="第三章-深度学习基础模型"><a href="#第三章-深度学习基础模型" class="headerlink" title="第三章 深度学习基础模型"></a>第三章 深度学习基础模型</h2><h3 id="基础知识——考点4"><a href="#基础知识——考点4" class="headerlink" title="基础知识——考点4"></a>基础知识——<em><strong>考点4</strong></em></h3><h4 id="神经元模型"><a href="#神经元模型" class="headerlink" title="神经元模型"></a>神经元模型</h4><p><img src="/2026/01/19/NLP/image-20260122224817434.png" alt="image-20260122224817434"></p>
<p>激活函数：Sigmoid&#x2F;Logistic, tanh ,ReLU, ELU。</p>
<h4 id="梯度下降法"><a href="#梯度下降法" class="headerlink" title="梯度下降法"></a>梯度下降法</h4><p>迭代调参思想：通过调整参数，让模型输出递归性地逼近标准输出。</p>
<ol>
<li>用误差定义损失函数L(θ)——定义目标函数</li>
<li>将问题转化为求极值问题求 minC(θ)——优化目标函数</li>
</ol>
<p>损失函数：0-1损失，平方损失函数，绝对值损失函数，对数损失函数，交叉熵，Hinge损失，指数损失。</p>
<p><img src="/2026/01/19/NLP/image-20260122225950378.png" alt="image-20260122225950378"></p>
<p>梯度下降中的问题：1.参数初值设置将影响参数学习效果避免各参数初值设为相同值，参数初值设置尽量随机。2.学习率 η 设置时要注意不能过大或过小</p>
<h4 id="反向传播算法"><a href="#反向传播算法" class="headerlink" title="反向传播算法"></a>反向传播算法</h4><p>如何求每一层的导数是一个问题</p>
<p><img src="/2026/01/19/NLP/image-20260122231858181.png" alt="image-20260122231858181"></p>
<p>首先计算最后层误差δL ，然后根据误差反传公式求得倒数第二层误差δL-1直至第一层。</p>
<p><img src="/2026/01/19/NLP/image-20260122232256206.png" alt="image-20260122232256206"></p>
<p><img src="/2026/01/19/NLP/image-20260122232058278.png" alt="image-20260122232058278"></p>
<p><strong>梯度消失问题</strong></p>
<p>在神经网络中误差反向传播的迭代公式需要用到激活函数的导数误差从输出层反向传播时每层都要乘激活函数导数。这样当激活函数导数值小于 1 时 ，误差经过每一层传递都会不断衰减，当网络很深时甚至消失。</p>
<p>解决方法：选择合适的激活函数、用复杂的门结构代替激活函数、残差结构</p>
<p><strong>梯度爆炸问题</strong></p>
<p>梯度爆炸是指在反向传播过程中，梯度值随着层数的增加而迅速增大，最终变得非常大，超出了神经网络的正常处理范围，从而导致模型参数更新不稳定，甚至训练失败。</p>
<p>梯度爆炸的原因主要包括权重初始化过大、网络层数过多以及学习率设置过高等</p>
<p>缓解措施：使用梯度裁剪、合理初始化权重、调整学习率并选择稳定的优化算法来降低梯度爆炸的风险。</p>
<p>过拟合是机器学习中常见的问题，指模型在训练数据上表现良好，但在新数据上表现不佳，导致泛化能力下降。</p>
<p><strong>过拟合的定义</strong></p>
<p>过拟合是指机器学习模型在训练数据上表现得非常好（例如，准确率极高），但在未见过的新数据（测试集或实际应用场景）上表现明显下降。这种现象的本质在于模型过度学习了训练数据中的噪声和特定样本特征，而不是学习到数据的普遍规律。</p>
<p>原因：模型复杂度过高、训练时间过长、数据量不足。</p>
<p>影响：过拟合会导致模型在新数据上的预测能力下降，无法准确分类或预测。这是机器学习模型的主要目标之一，即能够对未见过的数据进行有效的预测。</p>
<p>解决过拟合的方法：正则化、交叉验证、早停法、数据增强、简化模型。</p>
<h3 id="前馈神经网络DNN"><a href="#前馈神经网络DNN" class="headerlink" title="前馈神经网络DNN"></a>前馈神经网络DNN</h3><p><img src="/2026/01/19/NLP/image-20260122225136521.png" alt="image-20260122225136521"></p>
<h3 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h3><h3 id="图卷积神经网络"><a href="#图卷积神经网络" class="headerlink" title="图卷积神经网络"></a>图卷积神经网络</h3><h3 id="循环神经网络——考点3"><a href="#循环神经网络——考点3" class="headerlink" title="循环神经网络——考点3"></a>循环神经网络——<em><strong>考点3</strong></em></h3><p>核心概念：将处理问题在时序上分解为一系列相同的“单元”，单元的神经网络可以在时序上展开，且能将上一时刻的结果传递给下一时刻，整个网络按时间轴展开。即可变长。</p>
<p><img src="/2026/01/19/NLP/image-20260122234854214.png" alt="image-20260122234854214"></p>
<p>输入输出结构</p>
<p><img src="/2026/01/19/NLP/image-20260122235312301.png" alt="image-20260122235312301"></p>
<p>参数学习算法：<a target="_blank" rel="noopener" href="https://blog.csdn.net/qq_22841387/article/details/139283146">BPTT</a></p>
<h4 id="循环神经网络改进及变形"><a href="#循环神经网络改进及变形" class="headerlink" title="循环神经网络改进及变形"></a>循环神经网络改进及变形</h4><p>问题：距当前节点越远的节点对当前节点处理影响越小，无法建模长时间的依赖（循环神经网络的长期依赖问题 ）</p>
<p><strong>长短时记忆神经网络：LSTM（long short-term memory）</strong></p>
<p>LSTM 通过设计“门”结构实现保留信息和选择信息功能</p>
<p><img src="/2026/01/19/NLP/image-20260122235914787.png" alt="image-20260122235914787"></p>
<p><strong>GRU (Gated Recurrent Unit)</strong></p>
<p>LSTM 简化: 输入门和遗忘门合并为更新门（更新门决定隐状态保留放弃部分）</p>
<p><img src="/2026/01/19/NLP/image-20260123000055695.png" alt="image-20260123000055695"></p>
<p>其他变形：DeepRNN、Bidirectional RNNs、 Deep Bidirectional RNN</p>
<h2 id="第四章-语言模型-词向量"><a href="#第四章-语言模型-词向量" class="headerlink" title="第四章 语言模型+词向量"></a>第四章 语言模型+词向量</h2><h3 id="统计语言模型"><a href="#统计语言模型" class="headerlink" title="统计语言模型"></a>统计语言模型</h3><p>语言模型基本思想：用句子S&#x3D;w1,w2,…,wn 的概率 p(S) 刻画句子的合理性</p>
<p>n-gram 模型假设一个词的出现概率只与它前面的n-1个词相关</p>
<p>1元文法模型就是独立于历史</p>
<h3 id="神经语言模型"><a href="#神经语言模型" class="headerlink" title="神经语言模型"></a>神经语言模型</h3><p>使用DNN 学习模型参数 ：NNLM 模型</p>
<p>使用RNN 学习模型参数 ： RNNLM 模型</p>
<h4 id="NNLM"><a href="#NNLM" class="headerlink" title="NNLM"></a>NNLM</h4><p><img src="/2026/01/19/NLP/image-20260123002907686.png" alt="image-20260123002907686"></p>
<p>每求一个参数用一遍神经网络</p>
<h4 id="RNNLM——考点3"><a href="#RNNLM——考点3" class="headerlink" title="RNNLM——考点3"></a>RNNLM——<em><strong>考点3</strong></em></h4><p><img src="/2026/01/19/NLP/image-20260123003217678.png" alt="image-20260123003217678"></p>
<p><img src="/2026/01/19/NLP/image-20260123003411064.png" alt="image-20260123003411064"></p>
<p>随着模型逐个读入语料中的词w1;w2 ….隐藏层不断地更新为h(1),h(2)….. ,通过这种迭代推进方式，每个隐藏层实际上包含了此前所有上文的信息，相比NNLM 只能采用上文n 元短语作为近似，RNNLM 包含了更丰富的上文信息，也有潜力达到更好的效果。</p>
<h4 id="RNN语言模型变形"><a href="#RNN语言模型变形" class="headerlink" title="RNN语言模型变形"></a>RNN语言模型变形</h4><p>正向语言模型、反向语言模型、双向语言模型、单向多层RNN语言模型、双向多层RNN语言模型</p>
<h3 id="词向量"><a href="#词向量" class="headerlink" title="词向量"></a>词向量</h3><p>one-hot</p>
<p>不计算词之间的共现频度，直接用“基于词的上下文词来预测当前词”或“基于当前词预测上下文词”的方法构造构造<strong>低维稠密向量</strong>作为词的分布式表示 。</p>
<h2 id="第五章-NLP中的注意力机制"><a href="#第五章-NLP中的注意力机制" class="headerlink" title="第五章 NLP中的注意力机制"></a>第五章 NLP中的注意力机制</h2>
  </div>
  <div id=""></div>
</div>

<script>
  
Fancybox.bind('[data-fancybox="fancybox-gallery-img"]', {
  dragToClose: true,
  Toolbar: true,
  closeButton: "top",
  Image: {
    zoom: true,
  },
  on: {
    initCarousel: (fancybox) => {
      const slide = fancybox.Carousel.slides[fancybox.Carousel.page];
      fancybox.$container.style.setProperty(
        "--bg-image",
        `url("${slide.$thumb.src}")`
      );
    },
    "Carousel.change": (fancybox, carousel, to, from) => {
      const slide = carousel.slides[to];
      fancybox.$container.style.setProperty(
        "--bg-image",
        `url("${slide.$thumb.src}")`
      );
    },
  },
});
</script>

<style>
    #noneimg img {
        display: none;
        z-index: 9999;
        /* width: 600px !important; */
        min-width: 0%;
        max-width: 90%;
        max-height: 80%;
        border-radius: 0px;
        position: fixed;
        box-shadow: 0 0 0px #c3c3c300 !important;
        left: 0;
        top: 0;
        right: 0;
        bottom: 0;
        margin: auto !important;
    }

    @media screen and (max-width:600px) {
        #noneimg img {
            max-width: 88%
        }
    }
</style>

    <div class="post-paging">
    

    
    <a href="/2026/01/18/SoftwareSecurity/">
        <div class="post-paging-next">
            <span>下一篇</span>
            <p>软件安全原理</p>
        </div>
    </a>
    
</div>
</div>
		
<div class="footer">
	<div class="Copyright">
		©2026 By Ram. 主题：<a
			style="text-decoration: none;display: contents; color: #898F9F;"
			target="_blank" rel="noopener" href="https://github.com/79e/hexo-theme-quiet">Quiet</a>
	</div>
	<div class="contact">
		
		<a target="_blank" rel="noopener" href="https://github.com/RamBree">
			<img src="https://cdn.jsdelivr.net/gh/duogongneng/MyBlogImg/imggithub.png" alt="Quiet主题">
		</a>
		
	</div>
</div>

<script src="/js/gotop.js"></script>


<style type="text/css">
    @media screen and (min-width: 600px) {
        .goTop>span {
            display: flex;
            align-items: center;
            justify-content: center;
            border-radius: 10px;
            width: 40px;
            height: 40px;
            cursor: pointer;
            opacity: 0.8;
            background: rgba(18, 24, 58, 0.06);
            text-align: center;
            transition: border .5s;
            border: 1px solid rgba(18, 24, 58, 0.06);

            -moz-transition: border .5s;
            /* Firefox 4 */
            -webkit-transition: border .5s;
            /* Safari 和 Chrome */
            -o-transition: border .5s;
            /* Opera */
        }

        .goTop>span:hover {
            border: 1px solid #6680B3;
        }


        .goTop {
            position: fixed;
            right: 30px;
            bottom: 80px;
        }

        .goTop>span>svg {
            width: 20px;
            height: 20px;
            opacity: 0.7;
        }

    }

    @media screen and (max-width: 600px) {
        .goTop {
            display: none;
        }
    }
</style>
<div class="goTop" id="js-go_top">
    <span>
        <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24">
            <g>
                <path d="M13 12v8h-2v-8H4l8-8 8 8z"></path>
            </g>
        </svg>
    </span>
</div>
<script>
    $( '#js-go_top' )
	.gotoTop( {
		offset: 500,
		speed: 300,
		animationShow: {
			'transform': 'translate(0,0)',
			'transition': 'transform .5s ease-in-out'
		},
		animationHide: {
			'transform': 'translate(100px,0)',
			'transition': 'transform .5s ease-in-out'
		}
	} );
</script>


    <!-- Gitalk -->
    <script>
        const data = '{"clientID":"02b3c","clientSecret":"adfc7b4","repo":"gimment","owner":"duneng","admin":"duneng"}'
        const gitalk = new Gitalk({
            ...JSON.parse( data),
            id:location.pathname,
            distractionFreeMode:false
        })
        
        if(Boolean('false')){
            gitalk.render('gitalk-container')
        }
    </script>

<script>
	console.log('\n %c Hexo-Quiet 主题 %c https://github.com/79e/hexo-theme-quiet \n', 'color: #fadfa3; background: #030307; padding:5px 0;', 'background: #fadfa3; padding:5px 0;')
</script>
	</body>
</html>

